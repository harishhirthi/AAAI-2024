{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4adde6-0d3f-4ce4-9aa6-2101b8ba2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8441f45-7787-4153-8909-aaff665b7f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_223796/1990381454.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.dates as mdates\n",
    "from itertools import islice\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1defa-1c69-4496-b0dc-4ba835ba0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries.metrics import TimeSeriesScorer\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b26c46-e775-4544-966c-80175e0334de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeSeriesScorer.greater_is_better_internal = True\n",
    "\n",
    "class NRMSE(TimeSeriesScorer):\n",
    "   greater_is_better_internal = True\n",
    "   optimum = 0.0\n",
    "\n",
    "   def compute_metric(self, data_future, predictions, target, **kwargs):\n",
    "      return np.sqrt(np.mean(np.square(data_future[target] - predictions[\"mean\"]))) / data_future[target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471e9527-3f6d-48ff-9c54-e17996765315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipelining\n",
    "def get_batched_data_fn(sub_df,\n",
    "    batch_size: int = 128, \n",
    "    context_len: int = 168, \n",
    "    horizon_len: int = 24):\n",
    "    \n",
    "    examples = defaultdict(list)\n",
    "    num_examples = 0\n",
    "    for start in range(0, len(sub_df) - (context_len + horizon_len), horizon_len):\n",
    "      num_examples += 1\n",
    "      #examples[\"country\"].append(country)\n",
    "      examples[\"inputs\"].append(sub_df[\"y\"][start:(context_end := start + context_len)].tolist())\n",
    "      #examples[\"gen_forecast\"].append(sub_df[\"gen_forecast\"][start:context_end + horizon_len].tolist())\n",
    "      #examples[\"week_day\"].append(sub_df[\"week_day\"][start:context_end + horizon_len].tolist())\n",
    "      examples[\"outputs\"].append(sub_df[\"y\"][context_end:(context_end + horizon_len)].tolist())\n",
    "      examples['inputs_ts'].append(sub_df.index[start:(context_end := start + context_len)])\n",
    "      examples[\"outputs_ts\"].append(sub_df.index[context_end:(context_end + horizon_len)])\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2761c9-82b7-48f4-8c03-a399754c394d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forecast_building(df):\n",
    "    # Set numerical columns as float32\n",
    "    for col in df.columns:\n",
    "        # Check if column is not of string type\n",
    "        if df[col].dtype != 'object' and pd.api.types.is_string_dtype(df[col]) == False:\n",
    "            df[col] = df[col].astype('float32')\n",
    "    \n",
    "    # Create the Timeseries Dataframe\n",
    "    dataset = TimeSeriesDataFrame(df.reset_index())\n",
    "\n",
    "    backtest_dataset = dataset\n",
    "    prediction_length = 24  # Define your prediction length. We use 24 here since the data is of hourly frequency\n",
    "    num_samples = 100\n",
    "\n",
    "    train_data, test_data = backtest_dataset.train_test_split(prediction_length)\n",
    "\n",
    "    predictor = TimeSeriesPredictor(prediction_length=prediction_length).fit(\n",
    "    train_data,\n",
    "    hyperparameters={\n",
    "        \"AutoARIMA\": {\n",
    "            \"seasonal_period\": 168\n",
    "        }\n",
    "    },\n",
    "    skip_model_selection=True,\n",
    "    verbosity=0)\n",
    "    predictions = predictor.predict(train_data)\n",
    "    agg_metrics = predictor.evaluate(backtest_dataset, metrics=[\"RMSE\", \"MSE\", \"MAE\", \"MSE\", \"MAPE\", \"SMAPE\", NRMSE(), \"SQL\"])\n",
    "\n",
    "    res_all = pd.DataFrame(test_data[test_data.index.isin(predictions.index)].target)\n",
    "    res_all.columns = ['y_true']\n",
    "    res_all.insert(1, 'y_pred', predictions['mean'])\n",
    "    res_all_df = res_all.reset_index().drop('item_id', axis = 1).sort_values('timestamp')\n",
    "    \n",
    "    return res_all_df, agg_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cfabe-29a7-43c2-8008-ae2d1a274cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_building(df): \n",
    "    building_name = df.columns[0]\n",
    "    df.columns = ['y']\n",
    "    input_data = get_batched_data_fn(df, batch_size=500)\n",
    "    # print(input_data)\n",
    "    \n",
    "    windows_all = []\n",
    "    counter = 1\n",
    "    for inputs_ts, inputs, outputs_ts, outputs in zip(input_data['inputs_ts'], \n",
    "                                                      input_data['inputs'], \n",
    "                                                      input_data['outputs_ts'], \n",
    "                                                      input_data['outputs']):\n",
    "        \n",
    "        input_df = pd.DataFrame({'timestamp': inputs_ts, \n",
    "                                 'target': inputs})\n",
    "        \n",
    "        output_df = pd.DataFrame({'timestamp': outputs_ts, \n",
    "                                 'target': outputs})\n",
    "        combined = pd.concat([input_df, output_df], axis=0)\n",
    "        combined['item_id'] = str(building_name) + '_' + str(counter)\n",
    "        combined['item_id_no'] = counter\n",
    "        counter += 1\n",
    "        windows_all.append(combined)\n",
    "        \n",
    "    windows_all_df = pd.concat(windows_all)\n",
    "    windows_all_df.timestamp = pd.to_datetime(windows_all_df.timestamp)\n",
    "    windows_all_df.set_index('timestamp', inplace=True)\n",
    "    # windows_all_df.to_csv('windows_all_df0.csv')\n",
    "\n",
    "    res, agg_metrics = forecast_building(windows_all_df)\n",
    "    return res, agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b932a8-70c5-4217-abe2-4cc43f56c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "context_len = 168\n",
    "horizon_len = 24\n",
    "\n",
    "def process_file(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.set_index(['timestamp'])\n",
    "\n",
    "    if df.shape[1] < 2:\n",
    "        return None\n",
    "        \n",
    "    print(datetime.now(), df.shape, flush=True)\n",
    "\n",
    "    res_all = []\n",
    "    agg_metrics_all = []\n",
    "    \n",
    "    i = 0\n",
    "    for building_name in df.columns:\n",
    "        print(datetime.now(), i, '/', len(df.columns), building_name, flush=True)\n",
    "        df1 = df[[building_name]]\n",
    "        \n",
    "        res, agg_metrics = process_building(df1)\n",
    "        res['building'] = building_name\n",
    "        res['filename'] = filename\n",
    "        res_all.append(res)\n",
    "        \n",
    "        \n",
    "        agg_metrics_df = pd.DataFrame([agg_metrics])\n",
    "        agg_metrics_df.insert(0, 'building', building_name)\n",
    "        agg_metrics_df.insert(0, 'filename', filename)\n",
    "        agg_metrics_all.append(agg_metrics_df)\n",
    "\n",
    "        i += 1\n",
    "        if i % 5 == 0:\n",
    "            print(datetime.now(), 'Saving...')\n",
    "            res_all_df = pd.concat(res_all).round(6)\n",
    "            res_all_df = res_all_df.reset_index()\n",
    "            res_all_df = res_all_df.rename(columns={res_all_df.columns[0]: \"timestamp\" })\n",
    "            res_all_df.to_csv(f'forecasts/{dataset}/{os.path.basename(filename)}', index=False)            \n",
    "           \n",
    "\n",
    "            agg_metrics_all_df = pd.concat(agg_metrics_all).round(6)            \n",
    "            agg_metrics_all_df.to_csv(f'results/{dataset}/agg_metrics_{os.path.basename(filename)}', index=False)            \n",
    "    \n",
    "    \n",
    "    res_all_df = pd.concat(res_all).round(6)\n",
    "    res_all_df = res_all_df.reset_index()\n",
    "    res_all_df = res_all_df.rename(columns={res_all_df.columns[0]: \"timestamp\" })\n",
    "    res_all_df.to_csv(f'forecasts/{dataset}/{os.path.basename(filename)}', index=False)            \n",
    "           \n",
    "\n",
    "    agg_metrics_all_df = pd.concat(agg_metrics_all).round(6)   \n",
    "    agg_metrics_all_df.to_csv(f'results/{dataset}/agg_metrics_{os.path.basename(filename)}', index=False)                \n",
    "\n",
    "    return res_all_df, agg_metrics_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2737ab-fe6f-4f79-b482-aa77dd35b952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:45:04.190030 /home/user/New_Buildings_Datasets/Enernoc/csv-only/processed/enernoc.csv\n",
      "2024-11-13 16:45:04.314812 (8785, 100)\n",
      "2024-11-13 16:45:04.315904 0 / 100 767\n",
      "2024-11-13 16:45:21.024626 1 / 100 304\n",
      "2024-11-13 16:45:33.723965 2 / 100 399\n",
      "2024-11-13 16:45:50.513510 3 / 100 21\n",
      "2024-11-13 16:45:54.161100 4 / 100 805\n",
      "2024-11-13 16:45:57.252707 Saving...\n",
      "2024-11-13 16:45:57.428665 5 / 100 14\n",
      "2024-11-13 16:46:05.716487 6 / 100 404\n",
      "2024-11-13 16:46:08.902488 7 / 100 78\n",
      "2024-11-13 16:46:17.681951 8 / 100 731\n",
      "2024-11-13 16:46:21.997370 9 / 100 218\n",
      "2024-11-13 16:46:28.447783 Saving...\n",
      "2024-11-13 16:46:28.806146 10 / 100 366\n",
      "2024-11-13 16:46:40.395813 11 / 100 766\n",
      "2024-11-13 16:46:50.077614 12 / 100 197\n",
      "2024-11-13 16:46:55.868163 13 / 100 30\n",
      "2024-11-13 16:47:03.127748 14 / 100 742\n",
      "2024-11-13 16:47:06.066667 Saving...\n",
      "2024-11-13 16:47:06.600261 15 / 100 32\n",
      "2024-11-13 16:47:12.115537 16 / 100 137\n",
      "2024-11-13 16:47:17.548200 17 / 100 36\n",
      "2024-11-13 16:47:24.647312 18 / 100 9\n",
      "2024-11-13 16:47:32.859112 19 / 100 808\n",
      "2024-11-13 16:47:38.651818 Saving...\n",
      "2024-11-13 16:47:39.370064 20 / 100 391\n",
      "2024-11-13 16:47:51.636326 21 / 100 213\n",
      "2024-11-13 16:47:58.403585 22 / 100 236\n",
      "2024-11-13 16:48:05.394257 23 / 100 6\n",
      "2024-11-13 16:48:17.338277 24 / 100 224\n",
      "2024-11-13 16:48:25.411173 Saving...\n",
      "2024-11-13 16:48:26.297890 25 / 100 45\n",
      "2024-11-13 16:48:29.215227 26 / 100 771\n",
      "2024-11-13 16:48:34.405237 27 / 100 492\n",
      "2024-11-13 16:48:45.504714 28 / 100 384\n",
      "2024-11-13 16:48:55.150300 29 / 100 153\n",
      "2024-11-13 16:49:01.561006 Saving...\n",
      "2024-11-13 16:49:02.629861 30 / 100 136\n",
      "2024-11-13 16:49:07.620327 31 / 100 386\n",
      "2024-11-13 16:49:16.999579 32 / 100 51\n",
      "2024-11-13 16:49:28.742756 33 / 100 472\n",
      "2024-11-13 16:49:40.282033 34 / 100 281\n",
      "2024-11-13 16:49:52.501188 Saving...\n",
      "2024-11-13 16:49:53.728579 35 / 100 474\n",
      "2024-11-13 16:50:05.223441 36 / 100 697\n",
      "2024-11-13 16:50:10.123345 37 / 100 49\n",
      "2024-11-13 16:50:15.691877 38 / 100 755\n",
      "2024-11-13 16:50:19.402899 39 / 100 228\n",
      "2024-11-13 16:50:25.134901 Saving...\n",
      "2024-11-13 16:50:26.578638 40 / 100 427\n",
      "2024-11-13 16:50:38.567142 41 / 100 454\n",
      "2024-11-13 16:50:48.107887 42 / 100 690\n",
      "2024-11-13 16:50:51.595273 43 / 100 703\n",
      "2024-11-13 16:50:59.466856 44 / 100 259\n",
      "2024-11-13 16:51:05.298276 Saving...\n",
      "2024-11-13 16:51:06.900367 45 / 100 648\n",
      "2024-11-13 16:51:11.029385 46 / 100 341\n",
      "2024-11-13 16:51:28.501499 47 / 100 44\n",
      "2024-11-13 16:51:32.015910 48 / 100 275\n",
      "2024-11-13 16:51:38.220517 49 / 100 718\n",
      "2024-11-13 16:51:41.460954 Saving...\n",
      "2024-11-13 16:51:43.258088 50 / 100 25\n",
      "2024-11-13 16:51:46.714609 51 / 100 65\n",
      "2024-11-13 16:51:54.431677 52 / 100 455\n",
      "2024-11-13 16:52:05.014348 53 / 100 101\n",
      "2024-11-13 16:52:11.286803 54 / 100 673\n",
      "2024-11-13 16:52:16.429507 Saving...\n",
      "2024-11-13 16:52:18.414021 55 / 100 31\n",
      "2024-11-13 16:52:23.412890 56 / 100 10\n",
      "2024-11-13 16:52:26.239011 57 / 100 761\n",
      "2024-11-13 16:52:30.975576 58 / 100 478\n",
      "2024-11-13 16:52:41.250809 59 / 100 100\n",
      "2024-11-13 16:52:46.897932 Saving...\n",
      "2024-11-13 16:52:49.006335 60 / 100 22\n",
      "2024-11-13 16:52:53.613183 61 / 100 41\n",
      "2024-11-13 16:53:01.891354 62 / 100 496\n",
      "2024-11-13 16:53:14.723853 63 / 100 217\n",
      "2024-11-13 16:53:20.396895 64 / 100 144\n",
      "2024-11-13 16:53:25.463801 Saving...\n",
      "2024-11-13 16:53:27.801178 65 / 100 214\n",
      "2024-11-13 16:53:34.010802 66 / 100 512\n",
      "2024-11-13 16:53:55.779108 67 / 100 654\n",
      "2024-11-13 16:54:04.495412 68 / 100 363\n",
      "2024-11-13 16:54:20.556942 69 / 100 109\n",
      "2024-11-13 16:54:32.524661 Saving...\n",
      "2024-11-13 16:54:35.291474 70 / 100 116\n",
      "2024-11-13 16:54:42.310482 71 / 100 111\n",
      "2024-11-13 16:54:47.132594 72 / 100 55\n",
      "2024-11-13 16:54:50.112828 73 / 100 832\n",
      "2024-11-13 16:54:53.620012 74 / 100 401\n",
      "2024-11-13 16:55:02.685688 Saving...\n",
      "2024-11-13 16:55:05.295142 75 / 100 99\n",
      "2024-11-13 16:55:11.025600 76 / 100 270\n",
      "2024-11-13 16:55:16.410678 77 / 100 29\n",
      "2024-11-13 16:55:24.247608 78 / 100 400\n",
      "2024-11-13 16:55:33.452011 79 / 100 786\n",
      "2024-11-13 16:55:38.028777 Saving...\n",
      "2024-11-13 16:55:40.792963 80 / 100 186\n",
      "2024-11-13 16:55:46.617570 81 / 100 285\n",
      "2024-11-13 16:55:56.402143 82 / 100 12\n",
      "2024-11-13 16:56:04.225670 83 / 100 88\n",
      "2024-11-13 16:56:08.967675 84 / 100 744\n",
      "2024-11-13 16:56:21.436421 Saving...\n",
      "2024-11-13 16:56:24.390047 85 / 100 745\n",
      "2024-11-13 16:56:29.358873 86 / 100 13\n",
      "2024-11-13 16:56:36.411621 87 / 100 56\n",
      "2024-11-13 16:56:44.178509 88 / 100 103\n",
      "2024-11-13 16:56:51.462049 89 / 100 737\n",
      "2024-11-13 16:56:54.298358 Saving...\n",
      "2024-11-13 16:56:57.402300 90 / 100 484\n",
      "2024-11-13 16:57:06.595785 91 / 100 674\n",
      "2024-11-13 16:57:10.863209 92 / 100 8\n",
      "2024-11-13 16:57:14.154213 93 / 100 92\n",
      "2024-11-13 16:57:18.651716 94 / 100 339\n",
      "2024-11-13 16:57:31.211720 Saving...\n",
      "2024-11-13 16:57:34.528432 95 / 100 887\n",
      "2024-11-13 16:57:42.541160 96 / 100 42\n",
      "2024-11-13 16:57:50.103407 97 / 100 475\n",
      "2024-11-13 16:58:02.782007 98 / 100 765\n",
      "2024-11-13 16:58:06.915956 99 / 100 716\n",
      "2024-11-13 16:58:09.965746 Saving...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files_list = glob.glob('/home/user/New_Buildings_Datasets/Enernoc/csv-only/processed/*.csv')\n",
    "\n",
    "dataset = 'Enernoc-arima'\n",
    "os.makedirs(f'forecasts/{dataset}/', exist_ok = True)\n",
    "os.makedirs(f'results/{dataset}/', exist_ok = True)\n",
    "\n",
    "for filename in files_list:\n",
    "    print(datetime.now(), filename)\n",
    "    results = process_file(filename)\n",
    "    # if results is not None:\n",
    "    #     results.to_csv(f'../forecasts/{dataset}/{os.path.basename(filename)}', index=False)\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
